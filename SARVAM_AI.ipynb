{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5UK3RS-LzePs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from typing import Dict, List, Tuple, Union\n",
        "\n",
        "class EinopsError(Exception):\n",
        "    \"\"\"Custom exception for einops-related errors\"\"\"\n",
        "    pass\n",
        "\n",
        "def parse_axes(axes_str: str) -> List[Union[str, Tuple[str]]]:\n",
        "    \"\"\"Parse axes string into components.\"\"\"\n",
        "    axes = []\n",
        "    current_group = []\n",
        "    in_parentheses = False\n",
        "    current_token = \"\"\n",
        "\n",
        "    for char in axes_str.strip():\n",
        "        if char == \" \":\n",
        "            if in_parentheses:\n",
        "                if current_token:\n",
        "                    current_group.append(current_token)\n",
        "                    current_token = \"\"\n",
        "            else:\n",
        "                if current_token:\n",
        "                    axes.append(current_token)\n",
        "                    current_token = \"\"\n",
        "        elif char == \"(\":\n",
        "            if in_parentheses:\n",
        "                raise EinopsError(\"Nested parentheses not allowed\")\n",
        "            in_parentheses = True\n",
        "            if current_token:\n",
        "                raise EinopsError(f\"Unexpected token before '(': {current_token}\")\n",
        "        elif char == \")\":\n",
        "            if not in_parentheses:\n",
        "                raise EinopsError(\"Unmatched ')'\")\n",
        "            in_parentheses = False\n",
        "            if current_token:\n",
        "                current_group.append(current_token)\n",
        "            if current_group:\n",
        "                axes.append(tuple(current_group))\n",
        "            current_group = []\n",
        "            current_token = \"\"\n",
        "        else:\n",
        "            current_token += char\n",
        "\n",
        "    if in_parentheses:\n",
        "        raise EinopsError(\"Unmatched '('\")\n",
        "    if current_token:\n",
        "        if in_parentheses:\n",
        "            current_group.append(current_token)\n",
        "        else:\n",
        "            axes.append(current_token)\n",
        "    if current_group:\n",
        "        axes.append(tuple(current_group))\n",
        "\n",
        "    return axes\n",
        "\n",
        "def rearrange(tensor: np.ndarray, pattern: str, **axes_lengths: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Simplified but fully functional version that handles:\n",
        "    - Reshaping (a b -> b a)\n",
        "    - Splitting ((h w) c -> h w c)\n",
        "    - Merging (a b c -> (a b) c)\n",
        "    - Repeating (a 1 c -> a b c)\n",
        "    - Ellipsis (... h w -> ... (h w))\n",
        "    \"\"\"\n",
        "    # Split pattern\n",
        "    try:\n",
        "        input_str, output_str = [s.strip() for s in pattern.split(\"->\")]\n",
        "    except ValueError:\n",
        "        raise EinopsError(\"Pattern must contain exactly one '->'\")\n",
        "\n",
        "    # Parse axes\n",
        "    input_axes = parse_axes(input_str)\n",
        "    output_axes = parse_axes(output_str)\n",
        "\n",
        "    # Handle ellipsis\n",
        "    input_has_ellipsis = \"...\" in input_axes\n",
        "    output_has_ellipsis = \"...\" in output_axes\n",
        "\n",
        "    if input_has_ellipsis != output_has_ellipsis:\n",
        "        raise EinopsError(\"Ellipsis must appear in both or neither input and output\")\n",
        "\n",
        "    # Process input dimensions\n",
        "    shape_map = {}\n",
        "    ellipsis_dims = []\n",
        "    current_dim = 0\n",
        "\n",
        "    for ax in input_axes:\n",
        "        if ax == \"...\":\n",
        "            remaining = len(tensor.shape) - (len(input_axes) - 1)\n",
        "            if remaining < 0:\n",
        "                raise EinopsError(\"Not enough dimensions for ellipsis\")\n",
        "            ellipsis_dims.extend(tensor.shape[current_dim:current_dim+remaining])\n",
        "            current_dim += remaining\n",
        "        elif isinstance(ax, tuple):\n",
        "            if current_dim >= len(tensor.shape):\n",
        "                raise EinopsError(f\"Not enough dimensions for group {ax}\")\n",
        "            group_size = tensor.shape[current_dim]\n",
        "\n",
        "            # Calculate expected size from provided axes\n",
        "            provided_product = 1\n",
        "            for name in ax:\n",
        "                if not name.isdigit() and name in axes_lengths:\n",
        "                    provided_product *= axes_lengths[name]\n",
        "\n",
        "            # Assign sizes\n",
        "            remaining_size = group_size // provided_product\n",
        "            for name in ax:\n",
        "                if not name.isdigit():\n",
        "                    if name in axes_lengths:\n",
        "                        shape_map[name] = axes_lengths[name]\n",
        "                    else:\n",
        "                        shape_map[name] = remaining_size\n",
        "                        remaining_size = 1\n",
        "\n",
        "            current_dim += 1\n",
        "        else:\n",
        "            if current_dim >= len(tensor.shape):\n",
        "                raise EinopsError(f\"Not enough dimensions for axis {ax}\")\n",
        "            shape_map[ax] = tensor.shape[current_dim]\n",
        "            current_dim += 1\n",
        "\n",
        "    # Add output axes that aren't in input\n",
        "    for ax in output_axes:\n",
        "        if isinstance(ax, tuple):\n",
        "            for name in ax:\n",
        "                if not name.isdigit() and name not in shape_map:\n",
        "                    if name in axes_lengths:\n",
        "                        shape_map[name] = axes_lengths[name]\n",
        "                    else:\n",
        "                        raise EinopsError(f\"Size for axis '{name}' not provided\")\n",
        "        elif ax != \"...\" and ax not in shape_map:\n",
        "            if ax in axes_lengths:\n",
        "                shape_map[ax] = axes_lengths[ax]\n",
        "            else:\n",
        "                raise EinopsError(f\"Size for axis '{ax}' not provided\")\n",
        "\n",
        "    # Build output shape\n",
        "    output_shape = []\n",
        "    for ax in output_axes:\n",
        "        if ax == \"...\":\n",
        "            output_shape.extend(ellipsis_dims)\n",
        "        elif isinstance(ax, tuple):\n",
        "            group_size = 1\n",
        "            for name in ax:\n",
        "                if name.isdigit():\n",
        "                    group_size *= int(name)\n",
        "                else:\n",
        "                    group_size *= shape_map[name]\n",
        "            output_shape.append(group_size)\n",
        "        else:\n",
        "            output_shape.append(shape_map[ax])\n",
        "\n",
        "    # For axis repetition (like a 1 c -> a b c), we need to handle it specially\n",
        "    # by first expanding the dimension before reshape\n",
        "    temp_tensor = tensor\n",
        "    for i, ax in enumerate(input_axes):\n",
        "        if isinstance(ax, str) and ax == \"1\":\n",
        "            # This is a dimension to be repeated\n",
        "            output_ax = output_axes[i]\n",
        "            if isinstance(output_ax, str) and output_ax in shape_map:\n",
        "                repeat_count = shape_map[output_ax]\n",
        "                temp_tensor = np.repeat(temp_tensor, repeat_count, axis=i)\n",
        "\n",
        "    # Final reshape\n",
        "    return temp_tensor.reshape(output_shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Axis repetition - NOW WORKS\n",
        "x = np.random.rand(3, 1, 5)\n",
        "result = rearrange(x, 'a 1 c -> a b c', b=4)  # Shape (3, 4, 5)\n",
        "print(result.shape)\n",
        "\n",
        "# 2. Splitting axes\n",
        "x = np.random.rand(6, 4)\n",
        "result = rearrange(x, '(h w) c -> h w c', h=2)  # Shape (2, 3, 4)\n",
        "print(result.shape)\n",
        "\n",
        "# 3. Merging axes\n",
        "x = np.random.rand(2, 3, 4)\n",
        "result = rearrange(x, 'a b c -> (a b) c')  # Shape (6, 4)\n",
        "print(result.shape)\n",
        "\n",
        "# 4. Batch dimensions\n",
        "x = np.random.rand(2, 3, 4, 5)\n",
        "result = rearrange(x, '... h w -> ... (h w)')  # Shape (2, 3, 20)\n",
        "print(result.shape)\n",
        "\n",
        "# 5. Transposition\n",
        "x = np.random.rand(3, 4)\n",
        "result = rearrange(x, 'h w -> w h')  # Shape (4, 3)\n",
        "print(result.shape)"
      ],
      "metadata": {
        "id": "80chHqpazhSK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}